{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MATH50003 Numerical Analysis: Problem Sheet 5\n\nThis problem sheet explores positive definite matrices,\nCholesky decompositions, matrix norms, and the singular value decomposition.\n\nQuestions marked with a â‹† are meant to be completed without using a computer.\nProblems are denoted A/B/C to indicate their difficulty."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using LinearAlgebra, Plots, Test"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Positive definite matrices and Cholesky decompositions\n\n\n**Problem 1.1â‹† (C)** Use the Cholesky decomposition to determine\nwhich of the following matrices are symmetric positive definite:\n$$\n\\begin{bmatrix} 1 & -1  \\\\\n-1 & 3\n\\end{bmatrix}, \\begin{bmatrix} 1 & 2 & 2  \\\\\n2 & 1 & 2\\\\\n2 & 2 & 1\n\\end{bmatrix}, \\begin{bmatrix} 3 & 2 & 1  \\\\\n2 & 4 & 2\\\\\n1 & 2 & 5\n\\end{bmatrix}, \n\\begin{bmatrix} 4 & 2 & 2 & 1  \\\\\n2 & 4 & 2 & 2\\\\\n2 & 2 & 4 & 2 \\\\\n1 & 2 & 2 & 4\n\\end{bmatrix}\n$$\n\n\n\n**Problem 1.2â‹† (B)** Recall that an inner product $âŸ¨ğ±, ğ²âŸ©$ on $â„^n$\nover the reals $â„$ satisfies, for all $ğ±,ğ²,ğ³ âˆˆ â„$ and $a,b âˆˆ â„$:\n1. Symmetry: $âŸ¨ğ±, ğ²âŸ© = âŸ¨ğ², ğ±âŸ©$\n2. Linearity: $âŸ¨ağ±+bğ², ğ³âŸ© = a âŸ¨ğ±, ğ³âŸ©+ bâŸ¨ğ², ğ³âŸ©$\n3. Posive-definite: $âŸ¨ğ±, ğ±âŸ© > 0$\nProve that $âŸ¨ğ±, ğ²âŸ©$ is an inner product if and only if\n$$\nâŸ¨ğ±, ğ²âŸ© = ğ±^âŠ¤ K ğ²\n$$\nwhere $K$ is a symmetric positive definite matrix.\n\n\n\n**Problem 1.3â‹† (A)** Show that a matrix is symmetric positive definite if and only if it has a Cholesky\ndecomposition of the form\n$$\nA = U U^âŠ¤\n$$\nwhere $U$ is upper triangular with positive entries on the diagonal.\n\n\n\n**Problem 1.4â‹† (A)** Prove that the following $n Ã— n$ matrix is symmetric positive definite\nfor any $n$:\n$$\nÎ”_n := \\begin{bmatrix}\n2 & -1 \\\\\n-1 & 2 & -1 \\\\\n& -1 & 2 & â‹± \\\\\n&& â‹± & â‹± & -1 \\\\\n&&& -1 & 2\n\\end{bmatrix}\n$$\nDeduce its two Cholesky decompositions: $Î”_n = L_n L_n^âŠ¤ = U_n U_n^âŠ¤$ where\n$L_n$ is lower triangular and $U_n$ is upper triangular.\n\n\n\n**Problem 1.5 (B)** `SymTridiagonal(dv, eu)` is a type for representing symmetric tridiagonal\nmatrices (that is, `SymTridiagonal(dv, ev) == Tridiagonal(ev, dv, ev)`). Complete the following\nimplementation of `cholesky` to return a `Bidiagonal` cholesky factor in $O(n)$ operations, \nand check your result\ncompared to your solution of Problem 1.3 for `n = 1_000_000`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import LinearAlgebra: cholesky\n\n# return a Bidiagonal L such that L'L == A (up to machine precision)\ncholesky(A::SymTridiagonal) = cholesky!(copy(A))\n\n# return a Bidiagonal L such that L'L == A (up to machine precision)\n# You are allowed to change A\nfunction cholesky!(A::SymTridiagonal)\n    d = A.dv # diagonal entries of A\n    u = A.ev # sub/super-diagonal entries of A\n    T = float(eltype(A)) # return type, make float in case A has Ints\n    n = length(d)\n    ld = zeros(T, n) # diagonal entries of L\n    ll = zeros(T, n-1) # sub-diagonal entries of L\n\n    Bidiagonal(ld, ll, :L)\nend\n\nn = 1000\nA = SymTridiagonal(2*ones(n),-ones(n-1))\nL = cholesky(A)\n@test L â‰ˆ cholesky(Matrix(A)).L"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Matrix norms\n\n**Problem 2.1â‹† (B)** Prove the following:\n$$\n\\begin{align*}\n\\|A\\|_âˆ &= \\max_k \\|A[k,:]\\|_1 \\\\\n\\|A\\|_{1 â†’ âˆ} &= \\|\\hbox{vec}(A)\\|_âˆ = \\max_{kj} |a_{kj}|\n\\end{align*}\n$$\n\n\n\n\n**Problem 2.2â‹† (B)** For a rank-1 matrix $A = ğ± ğ²^âŠ¤$ prove that\n$$\n\\|A \\|_2 = \\|ğ±\\|_2 \\|ğ²\\|_2.\n$$\nHint: use the Cauchyâ€“Schwartz inequality.\n\n\n\n**Problem 2.3â‹† (B)** Show for any orthogonal matrix $Q âˆˆ â„^m$ and\nmatrix $A âˆˆ â„^{m Ã— n}$ that\n$$\n\\|Q A\\|_F = \\|A\\|_F\n$$\nby first showing that $\\|A \\|_F = \\sqrt{\\hbox{tr}(A^âŠ¤ A)}$ using the\n_trace_ of an $m Ã— m$ matrix:\n$$\n\\hbox{tr}(A) = a_{11} + a_{22} + â‹¯ + a_{mm}.\n$$\n\n\n\n## 3. Singular value decomposition\n\n**Problem 3.1â‹† (B)** Show that $\\|A \\|_2 â‰¤ \\|A\\|_F â‰¤Â \\sqrt{r} \\|A \\|_2$ where\n$r$ is the rank of $A$.\n\n\n\n**Problem 3.2 (A)** Consider functions sampled on a $(n+1) Ã— (n+1)$ 2D grid \n$(x_k,y_j) = (k/n, j/n)$ where $k,j = 0,â€¦,n$. \nFor $n = 100$, what is the lowest rank $r$ such that\nthe  best rank-$r$ approximation to the samples \nthat is accurate to within $10^{-5}$ accuracy for the following functions:\n$$\n(x + 2y)^2, \\cos(\\sin x {\\rm e}^y), 1/(x + y + 1), \\hbox{sign}(x-y)\n$$\nFor which examples does the answer change when $n = 1000$?\n\n\n\n**Problem 3.3â‹† (B)** For $A âˆˆ â„^{m Ã— n}$ define the _pseudo-inverse_:\n$$\nA^+ := V Î£^{-1} U^âŠ¤.\n$$\nShow that it satisfies the _Moore-Penrose conditions_:\n1. $A A^+ A = A$\n2. $A^+ A A^+ = A^+$\n3. $(A A^+)^âŠ¤  = A A^+$ and $(A^+ A)^âŠ¤ = A^+ A$\n\n\n\n**Problem 3.4â‹† (A)** Show for $A âˆˆ â„^{m Ã— n}$ with $m â‰¥ n$ and âŠ¤ rank\nthat $ğ± =  A^+ ğ›$ is the least squares solution, i.e., minimises $\\| A ğ± - ğ› \\|_2$.\nHint: extend $U$ in the SVD to be a square orthogonal matrix.\n\n\n\n**Problem 3.5â‹† (A)**\nIf $A âˆˆ â„^{m Ã— n}$ has a non-empty kernel there are multiple solutions to the least\nsquares problem as \nwe can add any element of the kernel. Show that $ğ± = A^+ ğ›$ gives the least squares solution\nsuch that $\\| ğ± \\|_2$ is minimised."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.7.0"
    },
    "kernelspec": {
      "name": "julia-1.7",
      "display_name": "Julia 1.7.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
