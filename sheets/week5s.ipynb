{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH50003 Numerical Analysis: Problem Sheet 5\n",
    "\n",
    "This problem sheet explores positive definite matrices,\n",
    "Cholesky decompositions, matrix norms, and the singular value decomposition.\n",
    "\n",
    "Questions marked with a ‚ãÜ are meant to be completed without using a computer.\n",
    "Problems are denoted A/B/C to indicate their difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:18.151674Z",
     "iopub.status.busy": "2022-03-03T20:43:17.667985Z",
     "iopub.status.idle": "2022-03-03T20:43:24.206583Z",
     "shell.execute_reply": "2022-03-03T20:43:24.206013Z"
    }
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, Plots, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Positive definite matrices and Cholesky decompositions\n",
    "\n",
    "\n",
    "**Problem 1.1‚ãÜ (C)** Use the Cholesky decomposition to determine\n",
    "which of the following matrices are symmetric positive definite:\n",
    "$$\n",
    "\\begin{bmatrix} 1 & -1  \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix}, \\begin{bmatrix} 1 & 2 & 2  \\\\\n",
    "2 & 1 & 2\\\\\n",
    "2 & 2 & 1\n",
    "\\end{bmatrix}, \\begin{bmatrix} 3 & 2 & 1  \\\\\n",
    "2 & 4 & 2\\\\\n",
    "1 & 2 & 5\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix} 4 & 2 & 2 & 1  \\\\\n",
    "2 & 4 & 2 & 2\\\\\n",
    "2 & 2 & 4 & 2 \\\\\n",
    "1 & 2 & 2 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "A matrix is symmetric positive definite (SPD) if and only if it has a Cholesky decomposition, so the task here is really just to compute Cholesky decompositions (by hand). Since our goal is to tell if the Cholesky decompositions exist, we do not have to compute $L_k$'s. We only need to see if the decomposition process can keep to the end.\n",
    "\n",
    "**Matrix 1**\n",
    "\n",
    "$$A_0=\\begin{bmatrix} 1 & -1  \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$A_1=3-\\frac{(-1)\\times(-1)}{1}>0$, so Matrix 1 is SPD.\n",
    "\n",
    "**Matrix 2**\n",
    "\n",
    "$$A_0=\\begin{bmatrix}\n",
    "1 & 2 & 2 \\\\\n",
    "2 & 1 & 2 \\\\\n",
    "2 & 2 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$A_1=\\begin{bmatrix}\n",
    "1&2\\\\\n",
    "2&1\n",
    "\\end{bmatrix}-\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}\\begin{bmatrix} 2 & 2 \\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "-3&-2\\\\\n",
    "-2&-3\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$A_1[1,1]<0$, so Matrix 2 is not SPD.\n",
    "\n",
    "**Matrix 3**\n",
    "\n",
    "$$A_0=\\begin{bmatrix}\n",
    "3 & 2 & 1 \\\\\n",
    "2 & 4 & 2 \\\\\n",
    "1 & 2 & 5\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$A_1=\n",
    "\\begin{bmatrix}\n",
    "4&2\\\\\n",
    "2&5\n",
    "\\end{bmatrix}-\\frac{1}{3}\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\begin{bmatrix} 2 & 1 \\end{bmatrix}=\\frac{1}{3}\n",
    "\\begin{bmatrix}\n",
    "8&4\\\\\n",
    "4&13\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$3A_2=13-\\frac{4\\times 4}{8}>0$, so Matrix 3 is SPD.\n",
    "\n",
    "**Matrix 4**\n",
    "\n",
    "$$A_0=\\begin{bmatrix}\n",
    "4 & 2 & 2 & 1 \\\\\n",
    "2 & 4 & 2 & 2 \\\\\n",
    "2 & 2 & 4 & 2 \\\\\n",
    "1 & 2 & 2 & 4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$A_1=\\begin{bmatrix}\n",
    "4&2&2\\\\\n",
    "2&4&2\\\\\n",
    "2&2&4\n",
    "\\end{bmatrix}-\\frac{1}{4}\\begin{bmatrix} 2 \\\\ 2 \\\\ 1 \\end{bmatrix}\\begin{bmatrix} 2 & 2 & 1 \\end{bmatrix}=\\frac{1}{4}\n",
    "\\begin{bmatrix}\n",
    "12&4&6\\\\\n",
    "4&12&6\\\\\n",
    "6&6&15\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$4A_2=\\begin{bmatrix}\n",
    "12&6\\\\\n",
    "6&15\n",
    "\\end{bmatrix}-\\frac{1}{12}\\begin{bmatrix} 4 \\\\ 6 \\end{bmatrix}\\begin{bmatrix} 4 & 6 \\end{bmatrix}=\\frac{4}{3}\n",
    "\\begin{bmatrix}\n",
    "8&3\\\\\n",
    "3&9\n",
    "\\end{bmatrix}$$\n",
    "$3A_3=9-\\frac{3\\times 3}{8}>0$, so Matrix 4 is SPD.\n",
    "\n",
    "We can check that we did this correctly by running the following in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:25.492687Z",
     "iopub.status.busy": "2022-03-03T20:43:24.208210Z",
     "iopub.status.idle": "2022-03-03T20:43:27.325298Z",
     "shell.execute_reply": "2022-03-03T20:43:27.324806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cholesky{Float64, Matrix{Float64}}\n",
       "U factor:\n",
       "2√ó2 UpperTriangular{Float64, Matrix{Float64}}:\n",
       " 1.0  -1.0\n",
       "  ‚ãÖ    1.41421"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky([1 -1; -1 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:27.350070Z",
     "iopub.status.busy": "2022-03-03T20:43:27.349376Z",
     "iopub.status.idle": "2022-03-03T20:43:27.351318Z",
     "shell.execute_reply": "2022-03-03T20:43:27.350640Z"
    }
   },
   "outputs": [],
   "source": [
    "# this throws an error when uncommented and run because the matrix is not SPD\n",
    "# cholesky([1 2 2; 2 1 2; 2 2 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:27.353849Z",
     "iopub.status.busy": "2022-03-03T20:43:27.353246Z",
     "iopub.status.idle": "2022-03-03T20:43:27.387867Z",
     "shell.execute_reply": "2022-03-03T20:43:27.387426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cholesky{Float64, Matrix{Float64}}\n",
       "U factor:\n",
       "3√ó3 UpperTriangular{Float64, Matrix{Float64}}:\n",
       " 1.73205  1.1547   0.57735\n",
       "  ‚ãÖ       1.63299  0.816497\n",
       "  ‚ãÖ        ‚ãÖ       2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky([3 2 1; 2 4 2; 1 2 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:27.389749Z",
     "iopub.status.busy": "2022-03-03T20:43:27.389178Z",
     "iopub.status.idle": "2022-03-03T20:43:27.430481Z",
     "shell.execute_reply": "2022-03-03T20:43:27.429607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cholesky{Float64, Matrix{Float64}}\n",
       "U factor:\n",
       "4√ó4 UpperTriangular{Float64, Matrix{Float64}}:\n",
       " 2.0  1.0      1.0      0.5\n",
       "  ‚ãÖ   1.73205  0.57735  0.866025\n",
       "  ‚ãÖ    ‚ãÖ       1.63299  0.612372\n",
       "  ‚ãÖ    ‚ãÖ        ‚ãÖ       1.62019"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky([4 2 2 1; 2 4 2 2; 2 2 4 2; 1 2 2 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**\n",
    "\n",
    "**Problem 1.2‚ãÜ (B)** Recall that an inner product $‚ü®ùê±, ùê≤‚ü©$ on $‚Ñù^n$\n",
    "over the reals $‚Ñù$ satisfies, for all $ùê±,ùê≤,ùê≥ ‚àà ‚Ñù$ and $a,b ‚àà ‚Ñù$:\n",
    "1. Symmetry: $‚ü®ùê±, ùê≤‚ü© = ‚ü®ùê≤, ùê±‚ü©$\n",
    "2. Linearity: $‚ü®aùê±+bùê≤, ùê≥‚ü© = a ‚ü®ùê±, ùê≥‚ü©+ b‚ü®ùê≤, ùê≥‚ü©$\n",
    "3. Posive-definite: $‚ü®ùê±, ùê±‚ü© > 0$\n",
    "Prove that $‚ü®ùê±, ùê≤‚ü©$ is an inner product if and only if\n",
    "$$\n",
    "‚ü®ùê±, ùê≤‚ü© = ùê±^‚ä§ K ùê≤\n",
    "$$\n",
    "where $K$ is a symmetric positive definite matrix.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "We begin by showing that $‚ü®ùê±, ùê≤‚ü© = ùê±^‚ä§ K ùê≤$ with $K$ spd defines an inner product. To do this we simply verify the three properties: For symmetry, we find\n",
    "$$ ‚ü®ùê±, ùê≤‚ü© = ùê±^‚ä§ Kùê≤ = ùê± \\cdot (Kùê≤) = (Kùê≤) \\cdot ùê±$$\n",
    "$$=  (Kùê≤)^‚ä§ ùê± = ùê≤^‚ä§ K^‚ä§ùê± = ùê≤^‚ä§ K ùê± = ‚ü®ùê≤, ùê±‚ü©.$$\n",
    "For linearity:\n",
    "$$ ‚ü®aùê±+bùê≤, ùê≥‚ü© = (aùê±+bùê≤)^‚ä§ Kùê≥ = (aùê±^‚ä§+bùê≤^‚ä§)Kùê≥$$\n",
    "$$ = aùê±^‚ä§ Kùê≥ + bùê≤^‚ä§ Kùê≥ = a‚ü®ùê±, ùê≥‚ü© + b‚ü®ùê≤, ùê≥‚ü©.$$\n",
    "Positive-definiteness of the matrix $K$ immediately yields $‚ü®ùê±, ùê±‚ü© = ùê±^‚ä§ K ùê± >0$. Now we turn to the converse result, i.e. that there exists a symmetric positive definite matrix $K$ for any inner product ‚ü®ùê±, ùê≤‚ü© such that it can be written as $‚ü®ùê±, ùê≤‚ü© = ùê±^‚ä§ K ùê≤$. Define the entries of $K$ by $K_{ij} = ‚ü®e_i, e_j‚ü©$ where $e_j$ is the $j$-th standard basis vector. Note that by linearity of the inner product any inner product on $‚Ñù^n$ can be written as $‚ü®ùê±, ùê≤‚ü© = \\sum_{k=0}^n \\sum_{l=0}^n x_k y_l ‚ü®e_k, e_l‚ü©$ by linearity. But with the elements of $K$ defined as above this is precisely \n",
    "$$‚ü®ùê±, ùê≤‚ü© = \\sum_{k=0}^n \\sum_{l=0}^n x_k K_{kl} y_l = ùê±^‚ä§ K ùê≤.$$\n",
    "What remains is to show that this $K$ is symmetric positive definite. Symmetry is an immediate conseqence of the symmetry of its elements, i.e. $K_{ij} = ‚ü®e_i, e_j‚ü© = ‚ü®e_j, e_i‚ü© = K_{ji}$. Finally, positive definiteness follows from the positive definiteness of the inner product $‚ü®ùê±, ùê±‚ü© > 0$ with $‚ü®ùê±, ùê±‚ü© = ùê±^‚ä§ K ùê±$.\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 1.3‚ãÜ (A)** Show that a matrix is symmetric positive definite if and only if it has a Cholesky\n",
    "decomposition of the form\n",
    "$$\n",
    "A = U U^‚ä§\n",
    "$$\n",
    "where $U$ is upper triangular with positive entries on the diagonal.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "\n",
    "\n",
    "We didn't discuss this but note that because a symmetric positive definite matrix has stricly positive eigenvalues: for a normalised\n",
    "eigenvector we have\n",
    "$$\n",
    "Œª = ŒªùêØ^‚ä§ ùêØ = ùêØ^‚ä§ K ùêØ > 0.\n",
    "$$\n",
    "Thus they are always invertible. Then note that any such matrix has a Cholesky decomposition of standard form $A = L L^‚ä§$ where $L$ is lower triangular. The inverse of this standard form Cholesky decomposition is then $A^{-1} = L^{-T} L^{-1}$, which is of the desired form since $L$ is lower triangular and $L^{-T}$ is upper triangular. The positive entries on the diagonal follow directly because this is the case for the Cholesky decomposition factors of the original matrix. Thus, since all symmetric positive definite matrices can be written as the inverses of a symmetric positive definite matrix, this shows that they all have a decomposition $A = U U^‚ä§$ (using the Cholesky factors of its inverse).\n",
    "\n",
    "Alternatively, we can replicate the procedure of computing the Cholesky decomposition beginning in the bottom right\n",
    "instead of the top left. Write:\n",
    "$$\n",
    "A = \\begin{bmatrix} K & ùêØ\\\\\n",
    "                    ùêØ^‚ä§ & Œ± \\end{bmatrix} = \n",
    "                    \\underbrace{\\begin{bmatrix} I & {ùêØ \\over \\sqrt{Œ±}} \\\\\n",
    "                                        & \\sqrt{Œ±}\n",
    "                                        \\end{bmatrix}}_{U_1}\n",
    "                    \\begin{bmatrix} K - {ùêØ ùêØ^‚ä§ \\over Œ±}  & \\\\\n",
    "                     & 1 \\end{bmatrix}\n",
    "                     \\underbrace{\\begin{bmatrix} I \\\\\n",
    "                      {ùêØ^‚ä§ \\over \\sqrt{Œ±}} & \\sqrt{Œ±}\n",
    "                                        \\end{bmatrix}}_{U_1^‚ä§}\n",
    "$$\n",
    "The induction proceeds as in the lower triangular case.\n",
    "\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 1.4‚ãÜ (A)** Prove that the following $n √ó n$ matrix is symmetric positive definite\n",
    "for any $n$:\n",
    "$$\n",
    "Œî_n := \\begin{bmatrix}\n",
    "2 & -1 \\\\\n",
    "-1 & 2 & -1 \\\\\n",
    "& -1 & 2 & ‚ã± \\\\\n",
    "&& ‚ã± & ‚ã± & -1 \\\\\n",
    "&&& -1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Deduce its two Cholesky decompositions: $Œî_n = L_n L_n^‚ä§ = U_n U_n^‚ä§$ where\n",
    "$L_n$ is lower triangular and $U_n$ is upper triangular.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "We first prove that $L_n$ is lower bidiagonal by induction. Let $A$ be a tridiagonal SPD matrix:\n",
    "\n",
    "$$A=\\left[\\begin{array}{c|ccc}\n",
    "\\alpha & \\beta & 0 & \\cdots \\\\\\hline\n",
    "\\beta  &       &   &        \\\\\n",
    "0      &       & K &        \\\\\n",
    "\\vdots &       &   &        \\\\\n",
    "\\end{array}\\right]$$\n",
    "where $K$ is again tridiagonal. Denote the Cholesky decomposition of $A$ by $A=LL^\\top$. Recalling the proof of the *Theorem (Cholesky & SPD)* from the lecture, we can write\n",
    "\n",
    "$$L=\\left[\\begin{array}{c|ccc}\n",
    "\\sqrt{\\alpha}               & & 0         & \\\\\\hline\n",
    "\\frac{\\beta}{\\sqrt{\\alpha}} & &           &        \\\\\n",
    "0                           & & \\tilde{L} &        \\\\\n",
    "\\vdots                      & &           &         \n",
    "\\end{array}\\right]$$\n",
    "where $\\tilde{L}$ satisfies $\\tilde{L}\\tilde{L}^\\top=K-\\begin{bmatrix} \\beta^2/\\alpha & \\mathbf{0} \\\\ \\mathbf{0} & \\mathbf{0} \\end{bmatrix}$ which is a tridiagonal matrix smaller than $A$. Since $L$ is lower bidiagonal when $A$ is $1\\times 1$, we know by induction that $L$ is lower bidiagonal for $A$ of any size.\n",
    "\n",
    "Once we know that $L_n$ is lower bidiagonal, we can write it as\n",
    "$$L_n=\\begin{bmatrix}\n",
    "a_1 & \\\\\n",
    "b_1 & \\ddots & \\\\\n",
    "    & \\ddots & \\ddots  & \\\\\n",
    "    &        & b_{n-1} & a_n\n",
    "\\end{bmatrix}$$\n",
    "which we substitute into $\\Delta_n=L_nL_n^\\top$ to get\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "a_1=\\sqrt{2}\\\\\n",
    "a_kb_k=-1\\\\\n",
    "b_{k}^2+a_{k+1}^2=2\n",
    "\\end{array}\\right.$$\n",
    "for $k=1,\\dots,n-1$.\n",
    "\n",
    "Now we solve the recurrence. Substituting the second equation into the third one:\n",
    "$$\\frac{1}{a_k^2}+a_{k+1}^2=2.$$\n",
    "Let $c_k=a_k^2$:\n",
    "$$\\frac{1}{c_k}+c_{k+1}=2.$$\n",
    "Consider the fixing point of this recurrence: $\\frac{1}{x}+x=2\\Longrightarrow(x-1)^2=0$ has the double root $x=1$ which hints us to consider $\\frac{1}{c_k-1}$. In fact, the recurrence is equivalent to\n",
    "$$\\frac{1}{c_{k+1}-1}=\\frac{1}{c_k-1}+1.$$\n",
    "Recalling that $c_1=1$, we know that $\\frac{1}{c_k-1}=k$. As a result, $c_k=(k+1)/k$, $a_k=\\sqrt{(k+1)/k}$ and $b_k=-\\sqrt{k/(k+1)}$, hence we know $L_n$.\n",
    "\n",
    "We can apply the same process to $U_n$, but this is a special case since flipping $\\Delta_n$ horizontally and vertically gives itself: $P\\Delta_nP^\\top=\\Delta_n$ where\n",
    "$$\n",
    "P=\\begin{bmatrix} & & 1 \\\\ & ‚ã∞ & \\\\ 1 & & \\end{bmatrix}\n",
    "$$\n",
    "is the permutation that reverses a vector. \n",
    "So we can also flip $L_n$ to get $U_n$:\n",
    "$$\n",
    "U_n=PL_nP\n",
    "$$\n",
    "so that $U_n U_n^‚ä§ = P L_n P P L_n^‚ä§ P = P Œî_n P = Œî_n$.\n",
    "\n",
    "Alternatively one can use the procedure from Problem 1.3. That is, write:\n",
    "$$\n",
    "Œî_n = \\begin{bmatrix} Œî_{n-1} & -ùêû_n \\\\\n",
    "                    -ùêû_n^‚ä§ & 2 \\end{bmatrix} = \n",
    "                    \\underbrace{\\begin{bmatrix} I & {-ùêû_n \\over \\sqrt{2}} \\\\\n",
    "                                        & \\sqrt{2}\n",
    "                                        \\end{bmatrix}}_{U_1}\n",
    "                    \\begin{bmatrix} Œî_{n-1} - {ùêû_n ùêû_n^‚ä§ \\over 2}  & \\\\\n",
    "                     & 1 \\end{bmatrix}\n",
    "                     \\underbrace{\\begin{bmatrix} I \\\\\n",
    "                      {ùêØ^‚ä§ \\over \\sqrt{Œ±}} & \\sqrt{Œ±}\n",
    "                                        \\end{bmatrix}}_{U_1^‚ä§}\n",
    "$$\n",
    "Continuing proceeds as above.\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 1.5 (B)** `SymTridiagonal(dv, eu)` is a type for representing symmetric tridiagonal\n",
    "matrices (that is, `SymTridiagonal(dv, ev) == Tridiagonal(ev, dv, ev)`). Complete the following\n",
    "implementation of `cholesky` to return a `Bidiagonal` cholesky factor in $O(n)$ operations, \n",
    "and check your result\n",
    "compared to your solution of Problem 1.3 for `n = 1_000_000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:27.433356Z",
     "iopub.status.busy": "2022-03-03T20:43:27.432429Z",
     "iopub.status.idle": "2022-03-03T20:43:30.130687Z",
     "shell.execute_reply": "2022-03-03T20:43:30.130021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: L ‚âà (cholesky(Matrix(A))).L\n",
       "   Evaluated: 1000√ó1000 Bidiagonal{Float64, Vector{Float64}}:\n",
       " diag: 1.4142135623730951  1.224744871391589  ‚Ä¶  1.0004998750624627\n",
       " sub: -0.7071067811865475  -0.8164965809277261  ‚Ä¶  -0.9994998749374592 ‚âà [1.4142135623730951 0.0 ‚Ä¶ 0.0 0.0; -0.7071067811865475 1.224744871391589 ‚Ä¶ 0.0 0.0; ‚Ä¶ ; 0.0 0.0 ‚Ä¶ 1.0005003753127755 0.0; 0.0 0.0 ‚Ä¶ -0.9994998749374592 1.0004998750624627]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LinearAlgebra: cholesky\n",
    "\n",
    "# return a Bidiagonal L such that L'L == A (up to machine precision)\n",
    "cholesky(A::SymTridiagonal) = cholesky!(copy(A))\n",
    "\n",
    "# return a Bidiagonal L such that L'L == A (up to machine precision)\n",
    "# You are allowed to change A\n",
    "function cholesky!(A::SymTridiagonal)\n",
    "    d = A.dv # diagonal entries of A\n",
    "    u = A.ev # sub/super-diagonal entries of A\n",
    "    T = float(eltype(A)) # return type, make float in case A has Ints\n",
    "    n = length(d)\n",
    "    ld = zeros(T, n) # diagonal entries of L\n",
    "    ll = zeros(T, n-1) # sub-diagonal entries of L\n",
    "\n",
    "    ## SOLUTION\n",
    "    ld[1]=sqrt(d[1])\n",
    "    for k=1:n-1\n",
    "        ll[k]=u[k]/ld[k]\n",
    "        ld[k+1]=sqrt(d[k+1]-ll[k]^2)\n",
    "    end\n",
    "    ## END\n",
    "\n",
    "    Bidiagonal(ld, ll, :L)\n",
    "end\n",
    "\n",
    "n = 1000\n",
    "A = SymTridiagonal(2*ones(n),-ones(n-1))\n",
    "L = cholesky(A)\n",
    "@test L ‚âà cholesky(Matrix(A)).L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrix norms\n",
    "\n",
    "**Problem 2.1‚ãÜ (B)** Prove the following:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\|A\\|_‚àû &= \\max_k \\|A[k,:]\\|_1 \\\\\n",
    "\\|A\\|_{1 ‚Üí ‚àû} &= \\|\\hbox{vec}(A)\\|_‚àû = \\max_{kj} |a_{kj}|\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "**Step 1. upper bounds**\n",
    "\n",
    "$$\\|A\\mathbf{x}\\|_\\infty=\\max_k\\left|\\sum_ja_{kj}x_j\\right|\\le\\max_k\\sum_j|a_{kj}x_j|\\le\n",
    "\\begin{cases}\n",
    "\\max\\limits_j|x_j|\\max\\limits_k\\sum\\limits_j|a_{kj}|=\\|\\mathbf{x}\\|_\\infty\\max\\limits_k\\|A[k,:]\\|_1\\\\\n",
    "\\max\\limits_{kj}|a_{kj}|\\sum\\limits_j|x_j|=\\|\\mathbf{x}\\|_1\\|\\text{vec}(A)\\|_\\infty\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Step 2.1. meeting the upper bound ($\\|A\\|_{1 ‚Üí ‚àû}$)**\n",
    "\n",
    "Let $a_{lm}$ be the entry of $A$ with maximum absolute value. Let $\\mathbf{x}=\\mathbf{e}_m$, then\n",
    "$$\\|A\\mathbf{x}\\|_\\infty=\\max_k\\left|\\sum_ja_{kj}x_j\\right|=\\max_k|a_{km}|=|a_{lm}|$$\n",
    "and\n",
    "$$\\|\\mathbf{x}\\|_1\\|\\text{vec}(A)\\|_\\infty=1\\cdot|a_{lm}|.$$\n",
    "\n",
    "\n",
    "**Step 2.2. meeting the upper bound ($\\|A\\|_‚àû$)**\n",
    "\n",
    "Let $A[n,:]$ be the row of $A$ with maximum 1-norm. Let $\\mathbf{x}=\\left(\\text{sign}.(A[n,:])\\right)^\\top$, then $\\left|\\sum_ja_{kj}x_j\\right|\\begin{cases} =\\sum_j|a_{kj}|=\\|A[k,:]\\|_1 & k=n \\\\ \\le\\sum_j|a_{kj}|=\\|A[k,:]\\|_1 & k\\ne n \\end{cases}$, so\n",
    "$$\\|A\\mathbf{x}\\|_\\infty=\\max_k\\left|\\sum_ja_{kj}x_j\\right|=\\max\\limits_k\\|A[k,:]\\|_1$$\n",
    "while\n",
    "$$\\|\\mathbf{x}\\|_\\infty\\max\\limits_k\\|A[k,:]\\|_1=1\\cdot\\max\\limits_k\\|A[k,:]\\|_1.$$\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "In both cases, equality can hold, so the upper bounds are actually maxima.\n",
    "\n",
    "**END**\n",
    "\n",
    "\n",
    "**Problem 2.2‚ãÜ (B)** For a rank-1 matrix $A = ùê± ùê≤^‚ä§$ prove that\n",
    "$$\n",
    "\\|A \\|_2 = \\|ùê±\\|_2 \\|ùê≤\\|_2.\n",
    "$$\n",
    "Hint: use the Cauchy‚ÄìSchwartz inequality.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "$$\\|A\\mathbf{z}\\|_2=\\|\\mathbf{x}\\mathbf{y}^\\top\\mathbf{z}\\|_2=|\\mathbf{y}^\\top\\mathbf{z}|\\|\\mathbf{x}\\|_2,$$\n",
    "so it remains to prove that $\\|\\mathbf{y}\\|_2=\\sup_{\\mathbf{z}}\\frac{|\\mathbf{y}^\\top\\mathbf{z}|}{\\|\\mathbf{z}\\|_2}$.\n",
    "\n",
    "By Cauchy-Schwartz inequality,\n",
    "$$|\\mathbf{y}^\\top\\mathbf{z}|=|(\\mathbf{y},\\mathbf{z})|\\le\\|\\mathbf{y}\\|_2\\|\\mathbf{z}\\|_2$$\n",
    "with the two sides being equal when $\\mathbf{y}$ and $\\mathbf{z}$ are linearly dependent, in which case the bound is tight.\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 2.3‚ãÜ (B)** Show for any orthogonal matrix $Q ‚àà ‚Ñù^m$ and\n",
    "matrix $A ‚àà ‚Ñù^{m √ó n}$ that\n",
    "$$\n",
    "\\|Q A\\|_F = \\|A\\|_F\n",
    "$$\n",
    "by first showing that $\\|A \\|_F = \\sqrt{\\hbox{tr}(A^‚ä§ A)}$ using the\n",
    "_trace_ of an $m √ó m$ matrix:\n",
    "$$\n",
    "\\hbox{tr}(A) = a_{11} + a_{22} + ‚ãØ + a_{mm}.\n",
    "$$\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "$$\\text{tr}(A^\\top A)=\\sum_k(A^\\top A)[k,k]=\\sum_k\\sum_jA^\\top[k,j]A[j,k]=\\sum_k\\sum_jA[j,k]^2=\\|A\\|_F^2.$$\n",
    "\n",
    "On the other hand,\n",
    "$$\\text{tr}(A^\\top A)=\\text{tr}(A^\\top Q^\\top QA)=\\text{tr}((QA)^\\top (QA))=\\|QA\\|_F^2,$$\n",
    "so $\\|Q A\\|_F = \\|A\\|_F$.\n",
    "\n",
    "**END**\n",
    "\n",
    "## 3. Singular value decomposition\n",
    "\n",
    "**Problem 3.1‚ãÜ (B)** Show that $\\|A \\|_2 ‚â§ \\|A\\|_F ‚â§¬†\\sqrt{r} \\|A \\|_2$ where\n",
    "$r$ is the rank of $A$.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "From Problem 2.3 use the fact that $\\|A \\|_F = \\sqrt{\\hbox{tr}(A^‚ä§ A)}$, where $A\\in \\mathbb{R}^{m\\times n}$.\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\\|A \\|_F^2 = \\hbox{tr}(A^‚ä§ A) = \\sigma_1^2 +...+\\sigma_m^2$$\n",
    "\n",
    "where $\\sigma_1\\ge...\\ge \\sigma_n \\ge 0$ are the singular values of $A$ and $\\sigma_i^2$ are the eigenvalues of $A^‚ä§ A$\n",
    "\n",
    "Knowing that $\\|A\\|_2^2 = \\sigma_1^2$ we have $\\|A \\|_2^2 ‚â§ \\|A\\|_F^2$\n",
    "\n",
    "Moreover, since if the rank of $A$ is $r$ we have that $\\sigma_{r+1}=...=\\sigma_m=0$ and we also know $\\sigma_1\\ge...\\ge \\sigma_n \\ge 0$, we have that\n",
    "\n",
    "$\\|A\\|_F^2 = \\sigma_1^2 +...+\\sigma_m^2 =\\sigma_1^2 +...+\\sigma_r^2 \\le r \\sigma_1^2 =r \\|A \\|_2^2$\n",
    "\n",
    "Hence,\n",
    "$$\n",
    "\\|A \\|_2 ‚â§ \\|A\\|_F ‚â§¬†\\sqrt{r} \\|A \\|_2.\n",
    "$$\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 3.2 (A)** Consider functions sampled on a $(n+1) √ó (n+1)$ 2D grid \n",
    "$(x_k,y_j) = (k/n, j/n)$ where $k,j = 0,‚Ä¶,n$. \n",
    "For $n = 100$, what is the lowest rank $r$ such that\n",
    "the  best rank-$r$ approximation to the samples \n",
    "that is accurate to within $10^{-5}$ accuracy for the following functions:\n",
    "$$\n",
    "(x + 2y)^2, \\cos(\\sin x {\\rm e}^y), 1/(x + y + 1), \\hbox{sign}(x-y)\n",
    "$$\n",
    "For which examples does the answer change when $n = 1000$?\n",
    "\n",
    "**SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T20:43:30.133217Z",
     "iopub.status.busy": "2022-03-03T20:43:30.132632Z",
     "iopub.status.idle": "2022-03-03T20:43:31.853032Z",
     "shell.execute_reply": "2022-03-03T20:43:31.852562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ‚â§ 1.0e-5 with n = 100\n",
      "Rank for f‚ÇÅ = 3\n",
      "Rank for f‚ÇÇ = 5\n",
      "Rank for f‚ÇÉ = 4\n",
      "Rank for f‚ÇÑ = 100\n",
      "Error ‚â§ 1.0e-5 with n = 1000\n",
      "Rank for f‚ÇÅ = 3\n",
      "Rank for f‚ÇÇ = 5\n",
      "Rank for f‚ÇÉ = 5\n",
      "Rank for f‚ÇÑ = 1000\n"
     ]
    }
   ],
   "source": [
    "#define functions\n",
    "f‚ÇÅ(x,y) = (x + 2 * y) ^ 2\n",
    "f‚ÇÇ(x,y) = cos(sin(x)*exp(y))\n",
    "f‚ÇÉ(x,y) = 1/(x + y + 1)\n",
    "f‚ÇÑ(x,y) = sign(x-y)\n",
    "\n",
    "#define n and error goal\n",
    "error = 1e-5\n",
    "\n",
    "#helper function to compute nxn samples\n",
    "function samples(f, n)\n",
    "    x = y = range(0, 1; length=n)\n",
    "    return f.(x,y')\n",
    "end\n",
    "\n",
    "#find minimum rank of f with precision œµ\n",
    "function find_min_rank(f, n, œµ)\n",
    "    œÉ = svdvals(samples(f, n))\n",
    "    for i in 1:length(œÉ)\n",
    "        if sum(œÉ[i:end]) <= œµ\n",
    "            return i-1\n",
    "        end\n",
    "    end\n",
    "    return length(œÉ)\n",
    "end\n",
    "\n",
    "\n",
    "n=100\n",
    "println(\"Error ‚â§ \", error, \" with n = \", n)\n",
    "println(\"Rank for f‚ÇÅ = \", find_min_rank(f‚ÇÅ, n, error))\n",
    "println(\"Rank for f‚ÇÇ = \", find_min_rank(f‚ÇÇ, n, error))\n",
    "println(\"Rank for f‚ÇÉ = \", find_min_rank(f‚ÇÉ, n, error))\n",
    "println(\"Rank for f‚ÇÑ = \", find_min_rank(f‚ÇÑ, n, error))\n",
    "\n",
    "\n",
    "n=1000\n",
    "println(\"Error ‚â§ \", error, \" with n = \", n)\n",
    "println(\"Rank for f‚ÇÅ = \", find_min_rank(f‚ÇÅ, n, error))\n",
    "println(\"Rank for f‚ÇÇ = \", find_min_rank(f‚ÇÇ, n, error))\n",
    "println(\"Rank for f‚ÇÉ = \", find_min_rank(f‚ÇÉ, n, error))\n",
    "println(\"Rank for f‚ÇÑ = \", find_min_rank(f‚ÇÑ, n, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**\n",
    "\n",
    "**Problem 3.3‚ãÜ (B)** Define the _pseudo-inverse_:\n",
    "$$\n",
    "A^+ := V Œ£^{-1} U^‚ä§.\n",
    "$$\n",
    "Show that it satisfies the _Moore-Penrose conditions_:\n",
    "1. $A A^+ A = A$\n",
    "2. $A^+ A A^+ = A^+$\n",
    "3. $(A A^+)^‚ä§  = A A^+$ and $(A^+ A)^‚ä§ = A^+ A$\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "Let $A=UŒ£ V^‚ä§$ and $A^+ := V Œ£^{-1} U^‚ä§$. Note that $UU^‚ä§ = U^‚ä§U = I$ ($U$ orthonormal) and $V^‚ä§ V =I$\n",
    "\n",
    "1. We have\n",
    "$$A A^+ A = U \\Sigma V^‚ä§ V \\Sigma^{-1} U^‚ä§ U \\Sigma V^‚ä§ = U \\Sigma \\Sigma^{-1} \\Sigma V^‚ä§ = U\\Sigma V^‚ä§ = A$$\n",
    "\n",
    "2. Moreover,\n",
    "$$A^+ A A^+ = V \\Sigma^{-1}U^‚ä§ U \\Sigma V^‚ä§ V \\Sigma^{-1} U^‚ä§ = V \\Sigma^{-1}\\Sigma \\Sigma^{-1} U^‚ä§ = V \\Sigma^{-1} U^‚ä§ = A^+$$\n",
    "\n",
    "3. Furthermore, $AA^+ = U \\Sigma V^‚ä§ V \\Sigma^{-1} U^‚ä§ = U U^‚ä§ = I$, thus\n",
    "\n",
    "$$(AA^+)^‚ä§ = I^‚ä§ = I = AA^+$$\n",
    "\n",
    "Moreover, $A^+A = V \\Sigma^{-1} U^‚ä§ U \\Sigma V^‚ä§ = VV^‚ä§$, hence,\n",
    "\n",
    "$$(A^+A)^‚ä§ = (VV^‚ä§)^‚ä§=VV^‚ä§=A^+A$$\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 3.4‚ãÜ (A)** Show for $A ‚àà ‚Ñù^{m √ó n}$ with $m ‚â• n$ and ‚ä§ rank\n",
    "that $ùê± =  A^+ ùêõ$ is the least squares solution, i.e., minimises $\\| A ùê± - ùêõ \\|_2$.\n",
    "Hint: extend $U$ in the SVD to be a square orthogonal matrix.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "The proof mimics that of the QR decomposition. Write $A =  U Œ£ V^‚ä§$ and let\n",
    "$$\n",
    "UÃÉ = [U K]\n",
    "$$\n",
    "so that $UÃÉ$ is orthogonal. We use the fact orthogonal matrices do not change norms:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\|A ùê± - ùêõ \\|_2^2 &= \\|U Œ£ V^‚ä§ ùê± - ùêõ \\|_2^2 = \\|UÃÉ^‚ä§ U Œ£ V^‚ä§ ùê± - UÃÉ^‚ä§ ùêõ \\|_2^2 = \\|\\underbrace{\\begin{bmatrix}I_m \\\\ O \\end{bmatrix}}_{‚àà ‚Ñù^{m √ó n}} Œ£ V^‚ä§ ùê± - \\begin{bmatrix} U^‚ä§ \\\\ K^‚ä§ \\end{bmatrix} ùêõ \\|_2^2 \\\\\n",
    "&= \\|Œ£ V^‚ä§ ùê± - U^‚ä§ ùêõ \\|_2^2 + \\|K^‚ä§ ùêõ\\|^2\n",
    "\\end{align*}\n",
    "$$\n",
    "The second term is independent of $ùê±$. The first term is minimised when zero:\n",
    "$$\n",
    " \\|Œ£ V^‚ä§ ùê± - U^‚ä§ ùêõ \\|_2 =\\|Œ£ V^‚ä§ V Œ£^{-1} U^‚ä§ ùêõ  - U^‚ä§ ùêõ \\|_2 = 0\n",
    "$$\n",
    "\n",
    "**END**\n",
    "\n",
    "**Problem 3.5‚ãÜ (A)**\n",
    "If $A ‚àà ‚Ñù^{m √ó n}$ has a non-empty kernel there are multiple solutions to the least\n",
    "squares problem as \n",
    "we can add any element of the kernel. Show that $ùê± = A^+ ùêõ$ gives the least squares solution\n",
    "such that $\\| ùê± \\|_2$ is minimised.\n",
    "\n",
    "**SOLUTION**\n",
    "\n",
    "Let $x=A^+b$ and take $y$ to be another solution i.e. $Ay=b$.\n",
    "\n",
    "Define $Q=A^+A$, then using 3.3\n",
    "\n",
    "$$Qx = A^+Ax=A^+AA^+b= A^+b=x$$\n",
    "\n",
    "and\n",
    "\n",
    "$$Q^‚ä§ = (A^+A)^‚ä§ = A^+A$$\n",
    "\n",
    "$$\\|y\\|_2^2 =  \\|x -(x-y)\\|_2^2= \\|x\\|_2^2 - 2(x, x-y) +  \\|x-y\\|_2^2 =  \\|x\\|_2^2 + \\|x-y\\|_2^2\\ge \\|x\\|_2^2$$\n",
    "\n",
    "since \n",
    "\n",
    "$$(x, x-y)= (Qx, x-y)=x^‚ä§Q^‚ä§(x-y)=x^‚ä§Q(x-y)=x^‚ä§(x-Qy)=x^‚ä§(x-A^+Ay)=x^‚ä§(x-A^+b)=x^‚ä§ 0 =0$$\n",
    "\n",
    "**END**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
